{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.meme-arsenal.com/memes/a33d72b526c94cc9b3f4b22044324dab.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://www.meme-arsenal.com/memes/a33d72b526c94cc9b3f4b22044324dab.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Задание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support, f1_score\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "from razdel import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/anna/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "russian_stopwords = stopwords.words(\"russian\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv', index_col=False)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data['comment'], data['toxic'], test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_vectorizer = CountVectorizer()\n",
    "x_train_tokens = default_vectorizer.fit_transform(x_train.values.tolist())\n",
    "x_test_tokens = default_vectorizer.transform(x_test.values.tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def razdel_tokenizer(text):\n",
    "    return [item.text for item in list(tokenize(text))]    \n",
    "custom_vectorizer = CountVectorizer(tokenizer=razdel_tokenizer)\n",
    "X_train_tokens = custom_vectorizer.fit_transform(x_train.values.tolist())\n",
    "X_test_tokens = custom_vectorizer.transform(x_test.values.tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1400)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logRegDefault = LogisticRegression(max_iter=1400)\n",
    "logRegRazdel = LogisticRegression(max_iter=1400)\n",
    "logRegDefault.fit(x_train_tokens, y_train)\n",
    "logRegRazdel.fit(X_train_tokens, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, попробуем измерить accuracy с помощью логистической регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default accuracy -  0.8504024424091036\n",
      "Razdel accuracy -  0.8542880932556203\n"
     ]
    }
   ],
   "source": [
    "print(\"Default accuracy - \", logRegDefault.score(x_test_tokens, y_test))\n",
    "print(\"Razdel accuracy - \", logRegRazdel.score(X_test_tokens, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разница совсем небольшая, разделовский токенайзер работает чуть лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также можно воспользоваться деревом решений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.85      0.81      2353\n",
      "         1.0       0.66      0.56      0.60      1250\n",
      "\n",
      "    accuracy                           0.75      3603\n",
      "   macro avg       0.72      0.70      0.71      3603\n",
      "weighted avg       0.74      0.75      0.74      3603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# метрика для разделовского токенайзера\n",
    "DTC = DecisionTreeClassifier()\n",
    "DTC.fit(X_train_tokens, y_train)\n",
    "\n",
    "DTC_preds = DTC.predict(X_test_tokens)\n",
    "print(classification_report(y_test, DTC_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.85      0.81      2353\n",
      "         1.0       0.66      0.55      0.60      1250\n",
      "\n",
      "    accuracy                           0.74      3603\n",
      "   macro avg       0.72      0.70      0.71      3603\n",
      "weighted avg       0.74      0.74      0.74      3603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# метрика для дефолтного токенайзера\n",
    "DTC.fit(x_train_tokens, y_train)\n",
    "\n",
    "\n",
    "DTC_preds = DTC.predict(x_test_tokens)\n",
    "print(classification_report(y_test, DTC_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы по второй метрике: дефолтный токенайзер и разделовский токенайзер почти не отличаются, мы видим только небольшие различия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итог: в принципе, если несколько раз от начала до конца делать RUN, то результаты метрики будут разными. Как я поняла, это из-за того, что в датасете может быть неравно сбалансированное количество токсичных и нетоксичных комментариев. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 задание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.quickmeme.com/img/6f/6f234c5b9c9feabe6da8f8a51fe49bc82e3f116287a526e7b6d5d4d34cc41dd1.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"http://www.quickmeme.com/img/6f/6f234c5b9c9feabe6da8f8a51fe49bc82e3f116287a526e7b6d5d4d34cc41dd1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/r5Nc2HC/abs-bow.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://i.ibb.co/r5Nc2HC/abs-bow.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = [[ 1,1,1,0,0,0],[1,1,1,0,0,0], [3,0,1,1,0,0],[1,0,0,1,1,0], [0,0,0,0,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablichka = pd.DataFrame(f, columns = ['я', 'ты', 'и', 'только', 'не', 'он'], index = ['я и ты','ты и я','я, я и только я', 'только не я', 'он'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ищем tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_tf(term, sent):\n",
    "    tf = []\n",
    "    tf = sent.count(term) / len(sent.split())\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ищем df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_idf(term, text): \n",
    "        df = 0\n",
    "        idf = []\n",
    "        for d in text:\n",
    "            if term in d:\n",
    "                df += 1\n",
    "                idf = math.log(len(text) / df) \n",
    "        return idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tfidf(term, sent, text): \n",
    "    tfidf = []\n",
    "    tfidf = count_tf(term, sent) * count_idf(term, text)\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablichka_tfidf = pd.DataFrame()\n",
    "\n",
    "for a in voc:\n",
    "    x = []\n",
    "    for b in text:\n",
    "        x.append(count_tfidf(a, b, text))\n",
    "    tablichka_tfidf[a] = x\n",
    "    \n",
    "tablichka_tfidf.index = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        я       ты         и    только        не        он\n",
      "я и ты           0.074381  0.30543  0.170275  0.000000  0.000000  0.000000\n",
      "ты и я           0.074381  0.30543  0.170275  0.000000  0.000000  0.000000\n",
      "я, я и только я  0.133886  0.00000  0.102165  0.183258  0.000000  0.000000\n",
      "только не я      0.074381  0.00000  0.000000  0.305430  0.536479  0.000000\n",
      "он               0.000000  0.00000  0.000000  0.000000  0.000000  1.609438\n"
     ]
    }
   ],
   "source": [
    "print (tablichka_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 задание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data['comment'], data['toxic'], test_size=0.25, shuffle=True)\n",
    "\n",
    "y = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7519379844961241"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_df=0.1, min_df=5, stop_words=russian_stopwords , max_features=4321, ngram_range=(1, 2))\n",
    "\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment)\n",
    "\n",
    "clf = LogisticRegression(dual=False, tol=0.0001, C=0.1,solver='lbfgs', class_weight='balanced')\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "predictions_1 = clf.predict(X_test)\n",
    "proba_1 = clf.predict_proba(X_test)\n",
    "\n",
    "f1_score(y_test, predictions_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7856365614798694"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=7000,min_df=5, max_df=0.6, ngram_range=(1, 2),tokenizer=razdel_tokenizer)\n",
    "\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment) \n",
    "\n",
    "clf = MultinomialNB(alpha=0.1, fit_prior=False, class_prior=None)\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "predictions_2 = clf.predict(X_test)\n",
    "proba_2 = clf.predict_proba(X_test)\n",
    "\n",
    "f1_score(y_test, predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toxic(probas):\n",
    "    probas = [p[1] for p in probas]\n",
    "    test['probas'] = probas\n",
    "    res_df = test.sort_values(by = 'probas', ascending = False)[:10]\n",
    "    res_df = res_df.reset_index(drop=True)\n",
    "    for i in range(10):\n",
    "        print('toxic:', res_df.loc[i].toxic)\n",
    "        print('comment: ', res_df.loc[i].comment)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-й классификатор\n",
      "toxic: 1.0\n",
      "comment:  Какие блять передергивания? Ты дебил блять зашел на шок-доску и удивляешься что над тобой издеваются. Тут нет твоих друзей, рачье тупорылое, тут тебя все ненавидят. Как же печет от таких необучаемых ебланов. Ты ковбой, твою жену ебут где-то нахуй, а дети гибнут на Украине. Понял, быдло ты ебаное?\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  БЕЛАРУСЬ, БЛЯТЬ, БЕЛАРУСЬ. СПИДОРСВИН, БЛЯТЬ. НЕПРОБИВАЕМАЯ ХОХЛИНА, СУКА. Какие-же хохлы дененераты, пиздец просто.\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  А нахуй ты тут персональный чатик устроил, дегенерат? Или ты сейчас каждому работяге, который зайдет в твой обоссаный тред будешь бежать доказывать в чем он не прав и как нужно сделать шоб было всё нормально ? Проблема травлятредов была озвучена ещё задолго до того, как ты и тебе подобные, кукарекающие про школьников, срыватели покровов засунул на этот сайт свой немытый ебальник. Правда для этого люди не разводили шитпостинг на овер 100 постов с переливанием из пустого в порожнее. b для этого подходит идеально - вот там со своими братьями по разуму и разводи драму, хоть на несколько тредов. Я кончил и закурил, можешь теперь маршировать нахуй.\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Блядь абу нахуй ссылай этих дегенератов в фаг, всем похуй на их шлюх\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Пиздец у быдла с пикабу сначала горело от негров на нулевой, теперь от скримеров, куда я нахуй попал, ебаные животные это БЭ, ЭТО РАНДОМ СУЧАРА, ТАМ НЕ ДОЛЖНО БЫТЬ ПРАВИЛ, ПОШЕЛ НАХУЙ\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Правильно, у рузке особый путь с духовностью и спидом как у негров, к черту этих белых идиотов, предлагаю всем русским обмазать себя углем чтобы не ассоциироваться с белыми. И правда, мы граничим, торгуем и путешествуем по белым странам, без которых бы эта страна превратилась в нищую помойку с технологиями уровня 19 века. Какие же ебаные дегенераты иногда открывают свой рот, уверен что ни у немцев, ни у поляков с французами даже и в мыслях нет зачем нам эти белые, мы не белые, особый путь кукареку , брысь отсюда дугинистское червеобразное.\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Да тупая баба. Видос недавно был: мразь какая то девку у прилавка схватил и говорит отдай деньги, а то я ее зарежу. А ебанутая сука ему говорит Ах перестань хулиганить. И даже когда он телку ножом хуярить начал, она его из ведрышка поливала и шваброй стукнуть пыталась. Пока он ее саму ножом не уебал, до тупой суки не доходило, что при ней человека убивали. Какая слабина, диванные воены? Отдайте все что нужно и вызывайте полицию. Рэмбы комнатные.\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Я тебе дохуя пруфов привёл, а ты ебанный дебил не верил. Сося должен был вам сказать, но сося долбаёб и тебя за человека не держит, почему он тебе должен рассказывать о своих фейл, если его заявляения раньше звучали гордо . Ебать ты дибил.\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Путин - не Пыня. Повторяю. Путин - не пыня Даю установку, задержите дыхание, смотрите на экран П У Т И Н Н Е П Ы Н Я Все ясно, либерахи? Не пыня Путин, Пыня это Сисян.\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Лол, совковая пидораха полыхает, но аргументов кроме ДА ВЫ ЖЫ НИЧИГО НИ ПАНИМАИТИ не принес. Рашка сейчас - это совок, который воюет с другими странами (привет, Афганистан), экономика катится в жопу (привет, дефицит), запрещает иностранные товары (привет, совковые пидорахи, готовые дать в жопу за джинсы), и все это на фоне политического болота (привет, Леонид Ильич)\n",
      "\n",
      "2-й классификатор\n",
      "toxic: 1.0\n",
      "comment:  БЕЛАРУСЬ, БЛЯТЬ, БЕЛАРУСЬ. СПИДОРСВИН, БЛЯТЬ. НЕПРОБИВАЕМАЯ ХОХЛИНА, СУКА. Какие-же хохлы дененераты, пиздец просто.\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Блядь абу нахуй ссылай этих дегенератов в фаг, всем похуй на их шлюх\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Целью встречи стали переговоры о сохранении поставок газа А что, у него есть полномочия вести такие переговоры? Сука блядский цирк. Какие же хохлы дегенераты, пиздец просто\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Какие блять передергивания? Ты дебил блять зашел на шок-доску и удивляешься что над тобой издеваются. Тут нет твоих друзей, рачье тупорылое, тут тебя все ненавидят. Как же печет от таких необучаемых ебланов. Ты ковбой, твою жену ебут где-то нахуй, а дети гибнут на Украине. Понял, быдло ты ебаное?\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  залетуха плиз, если ты так любишь покой, то ты бы вспомнил лето и осень, когда даун на модере тер АБСОЛЮТНО все, а так ты просто даун который очередной раз разжигаешь срач и тебе похуй на реакшены, главное просто повыебываться и посрать.\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  КОНЧ, долбаёб. Их словечко. Соси хуй, я ебал твою мать.\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  НАКОНЕЦ-ТО! ГОРИ В АДУ, СУКА!\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Анастасия Афанасьевна старая тупая сука\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  предлагаю пидорнуть хохлов, хохлы не имеют отношения к политике постят всякую хуйню безграмотную и блевотную\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Ебать тебя разносит, шизик.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('1-й классификатор')\n",
    "clf1 = toxic(proba_1)\n",
    "print('2-й классификатор')\n",
    "clf2 = toxic(proba_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ytimg.com/vi/7twy1gjLR6A/hqdefault.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://i.ytimg.com/vi/7twy1gjLR6A/hqdefault.jpg\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "JjhLJimpacTi",
    "J89oTkOKacTo",
    "P7tD_YjJacTo",
    "--uh0bMFacTp",
    "i2Au_ny0acTr",
    "Dbv-iio7acTs",
    "V3sjcVMKacTt",
    "uMugd4w4acTx",
    "OgGnW4_kacTz",
    "qyb47c62acTz"
   ],
   "name": "Data_types.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
